{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "183fep_N2ucR3ul8r6cQ2CxN4dtcSLtwP",
      "authorship_tag": "ABX9TyNYO62HuAij1liJvkUGxv6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayR1031/reinforcement-language-model/blob/main/Reinforcement_Learning_with_Language_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmG7e--2ac7f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #for reading CSV dataset\n",
        "import random  # For random sampling in generation\n",
        "from collections import defaultdict, Counter #For counting n-gram transitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==== Build Corpus From CSV ==="
      ],
      "metadata": {
        "id": "LAudJP5je54J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_corpus_from_csv(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    fields_to_use = ['Title', 'ExperienceLevel', 'Skills', 'Responsibilities', 'Keywords']\n",
        "    def clean_and_combine_fields(row, fields):\n",
        "        combined = []\n",
        "        for field in fields:\n",
        "            val = str(row[field]) if pd.notnull(row[field]) else ''\n",
        "            val = val.replace(';', ',')\n",
        "            val = val.replace('\\n', '').replace('\\r', '')\n",
        "            combined.append(val.strip())\n",
        "        return ' '.join(combined)\n",
        "    corpus_list = [clean_and_combine_fields(row, fields_to_use) for _, row in df.iterrows()]\n",
        "    eos_token = '<EOS>'\n",
        "    corpus = f'{eos_token} '.join(corpus_list) + f' {eos_token}'\n",
        "    return corpus\n"
      ],
      "metadata": {
        "id": "ofP31e_Ke0BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==== Character N-Gram Language Model ===="
      ],
      "metadata": {
        "id": "p8-PQQ5vjrKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharNGramLanguageModel:\n",
        "    def __init__(self, n, text):\n",
        "        self.n = n\n",
        "        self.model = defaultdict(Counter)\n",
        "        eos_token = ' '\n",
        "\n",
        "    def update_probs_with_min_plus_one(self):\n",
        "        #converts raw counts to positive, normalizes weights\n",
        "        self.probs = {}\n",
        "        for context, counter  in self.model.items():\n",
        "            min_count = min(counter.values())\n",
        "            #subtract min and add 1: ensures every weight is >= 1\n",
        "            new_counts = {char: count - min_count + 1 for char, count in counter.items()}\n",
        "            total_count = sum(new_counts.values())\n",
        "            self.probs[context] = {char: val / total_count for char, val in new_counts.items()}\n",
        "\n",
        "    def generate_character(self, prompt):\n",
        "        context = prompt [-self.n:]\n",
        "        #Ensures probabilities are updated before generation\n",
        "        if context in self.probs:\n",
        "            choices, weights = zip(*self.probs[context].items())\n",
        "            #Pick next char using weighted probabilities\n",
        "            return random.choices(choices, weights=weights)[0]\n",
        "        else:\n",
        "            #Back-off: unseen context, pick at random\n",
        "            return random.choice(list('abcdefghijklmnopqrstuvwxyz'))\n",
        "\n",
        "    def generate(self, prompt, max_len=200):\n",
        "        result = prompt\n",
        "        for _ in range(max_len):\n",
        "            next_char = self.generate_character(result)\n",
        "            if next_char == '<EOS>':\n",
        "                break\n",
        "            result += next_char\n",
        "        return result"
      ],
      "metadata": {
        "id": "Bq1grWCFjmGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_probs_with_min_plus_one(self):\n",
        "        #converts raw counts to positive, normalizes weights\n",
        "        self.probs = {}\n",
        "        for context, counter  in self.model.items():\n",
        "            min_count = min(counter.values())\n",
        "            #subtract min and add 1: ensures every weight is >= 1\n",
        "            new_counts = {char: count - min_count + 1 for char, count in counter.items()}\n",
        "            total_count = sum(new_counts.values())\n",
        "            self.probs[context] = {char: val / total_count for char, val in new_counts.items()}"
      ],
      "metadata": {
        "id": "iu9fvZnDxG4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_character(self, prompt):\n",
        "    context = prompt[-self.n:]\n",
        "    if context in self.probs:\n",
        "        choices, weights = zip(*self.probs[context].items())\n",
        "        return random.choices(choices, weights=weights)[0]\n",
        "    else:\n",
        "        # Back-off must include <EOS>\n",
        "        return random.choice(list('abcdefghijklmnopqrstuvwxyz <EOS>'))\n"
      ],
      "metadata": {
        "id": "CBpD2VGqta4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(self, prompt, max_len=200):\n",
        "    result = prompt\n",
        "    for _ in range(max_len):\n",
        "        next_char = self.generate_character(result)\n",
        "        if next_char == '<EOS>':\n",
        "            break\n",
        "        result += next_char\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "bsq3Cr2rus1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#==== Reinforcement Learning for N-gram Model ==="
      ],
      "metadata": {
        "id": "qkeP07BmvI_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReinforcementLearning:\n",
        "    def __init__(self, model, alpha=0.1, gamma=0.9):\n",
        "        self.model = model # CharNGramLanguageModel\n",
        "        self.alpha = alpha # Learning rate\n",
        "        self.gamma = gamma # Discount Factor (not used but can be)\n",
        "\n",
        "\n",
        "    def Q_learning(self, criteria, num_prompts=1, iterations_per_prompts=30):\n",
        "        #Apply Q-Learning to update n-gram weights based on reward\n",
        "        for _ in range(num_prompts):\n",
        "            prompt = input(\"Enter a prompt for RL training: \")\n",
        "            for _ in range(iterations_per_prompts):\n",
        "                generated = self.model.generate(prompt, max_len=200)\n",
        "                reward = criteria(generated)\n",
        "                #Update model weights for each context/next_char in generated sequence\n",
        "                for i in range(len(generated) - self.model.n):\n",
        "                    context = generated[i:i+self.model.n]\n",
        "                    next_char = generated[i + self.model.n]\n",
        "                    #Basic Q-update: add (alpha * reward) to weight\n",
        "                    self.model.model[context][next_char] += self.alpha * reward\n",
        "        #After RL training, convert all counts to positive, normalized probabilities\n",
        "        self.model.update_probs_with_min_plus_one()\n"
      ],
      "metadata": {
        "id": "XxuS2oZmvSGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 5. Testing Function ====\n",
        "def test_model(model, prompt, num_samples=10):\n",
        "    lengths = []\n",
        "    samples = []\n",
        "    for _ in range(num_samples):\n",
        "        generated = model.generate(prompt, max_len=200)\n",
        "        lengths.append(len(generated))\n",
        "        samples.append(generated)\n",
        "    print(f\"Average length: {sum(lengths)/num_samples:.2f}\")\n",
        "    print(\"Sample generated text:\", samples[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "TxAovgWpyJiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 6. Main Workflow: Train and Test Model ====\n",
        "\n",
        "# -- Prepare training corpus --\n",
        "csv_path = \"/content/job_dataset.csv\"         # Update as needed\n",
        "corpus = build_corpus_from_csv(csv_path)"
      ],
      "metadata": {
        "id": "VV_X9ZXfyPLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Train base model --\n",
        "n = 5\n",
        "model = CharNGramLanguageModel(n, corpus)\n",
        "model.update_probs_with_min_plus_one()   # Initial positive weights for sampling"
      ],
      "metadata": {
        "id": "6AmJOWCGyaBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Test model BEFORE RL --\n",
        "prompt = \"Python Programming\"\n",
        "print(\"Testing BEFORE RL:\")\n",
        "test_model(model, prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDWu3UJGyysm",
        "outputId": "35a74ee1-31b5-465d-b5f8-940555c9a02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing BEFORE RL:\n",
            "Average length: 218.00\n",
            "Sample generated text: Python Programmingqwygsciwwiluymvlnessrsgauaqmtkytlnzfxdhpyylztvbpljjohagzolwcrbsyntuoaipxmwspqskotgsnowyieweckpqnvrvowbyxhqnhkcxizxitxgsxzecyvpkeubkofkxdonjvlnfshzqxxqjklmwxuzggkrsdrdszgpkpkbgwkpajdbtyzsejntiruktnfosd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Apply RL with criteria: shorter text will be rewarded using -len(x) --\n",
        "rl = ReinforcementLearning(model)\n",
        "rl.Q_learning(lambda x: -len(x), num_prompts=1, iterations_per_prompts=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpMCt3l0y2n6",
        "outputId": "f8045233-ba02-4c82-bff7-de64c2346acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a prompt for RL training: Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Test model AFTER RL --\n",
        "print(\"Testing AFTER RL:\")\n",
        "test_model(model, prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYr10jkYy5tI",
        "outputId": "8f75e381-02a2-4dd9-c14d-5cd270c968cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing AFTER RL:\n",
            "Average length: 218.00\n",
            "Sample generated text: Python Programmingbxopizhnvobjlpzcmqyhigyxkpsbtzlseinpabljnirrensyzwaiuafcljvauhkbxgrrnpwafwrynmjpsgrjblzlpvhlevxovbdizwaxcfiktpkuhbogldkkjoxzkadjvurrmdppzmfjdohzxsizvcwffpxcvyebpgsqeyakspcakpqqernmesinugtrbdojldasqnth\n"
          ]
        }
      ]
    }
  ]
}